{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adapted our code from the following: https://www.tensorflow.org/tutorials/generative/pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "physical_devices\n",
    "tf.config.set_visible_devices(physical_devices[2],'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import glob\n",
    "from skimage.transform import resize as rsz\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nifti to images for training\n",
    "# preprocessing\n",
    "\n",
    "for kind in ['Train','Val']:\n",
    "    train_data_path=f'{kind}_Dataset'\n",
    "    patients = os.listdir(train_data_path)\n",
    "#     print(patients)\n",
    "\n",
    "    for patient in patients:\n",
    "        print(f'WORKING ON PATIENTS: {patient}')\n",
    "        \n",
    "        study_type = os.listdir(os.path.join(train_data_path,patient))\n",
    "        patient_path = os.path.join(train_data_path,patient,study_type[0])\n",
    "        scans =os.listdir(os.path.join(train_data_path,patient))\n",
    "\n",
    "        ## Create the folders to store pngs \n",
    "        png_path= f'{kind.lower()}_FLAIR_2_T2_pngs'\n",
    "#         os.mkdir(png_dir)\n",
    "\n",
    "        ## Create the numpy arrays to pngs \n",
    "        for scan in scans:\n",
    "            if 't2.nii.gz' in scan:\n",
    "                t2path=os.path.join(patient_path,scan)\n",
    "#                 print(t2path)\n",
    "\n",
    "                t2_img = nib.load(t2path)\n",
    "                t2_imgdata = t2_img.get_fdata()\n",
    "                t2_imgdata = t2_imgdata.astype(np.float)\n",
    "                t2_affine = t2_img.affine\n",
    "\n",
    "                resized_t2_imgdata = rsz(t2_imgdata, (256, 256), order = 1, preserve_range=True)\n",
    "\n",
    "                resized_t2_imgdata -= resized_t2_imgdata.min()\n",
    "                resized_t2_imgdata *= 1./np.max(resized_t2_imgdata)\n",
    "                resized_t2_imgdata *= 255\n",
    "                resized_t2_imgdata = np.flipud(resized_t2_imgdata)\n",
    "\n",
    "\n",
    "            if 'flair.nii.gz' in scan:\n",
    "                flairpath=os.path.join(patient_path,scan)\n",
    "#                 print(flairpath)\n",
    "\n",
    "                flair_img = nib.load(flairpath)\n",
    "                flair_imgdata = flair_img.get_fdata()\n",
    "                flair_imgdata = flair_imgdata.astype(np.float)\n",
    "#                 print(flair_imgdata.shape)\n",
    "\n",
    "                resized_flair_imgdata = rsz(flair_imgdata, (256, 256), order = 1, preserve_range=True)\n",
    "\n",
    "                resized_flair_imgdata -= resized_flair_imgdata.min()\n",
    "                resized_flair_imgdata *= 1./np.max(resized_flair_imgdata)\n",
    "                resized_flair_imgdata *= 255\n",
    "                resized_flair_imgdata = np.flipud(resized_flair_imgdata)\n",
    "#                 print(resized_flair_imgdata.shape)\n",
    "#                 print(resized_flair_imgdata.min(),resized_flair_imgdata.max())\n",
    "\n",
    "        ## Use the numpy arrays to pngs              \n",
    "        for i in range(0,flair_imgdata.shape[2]):\n",
    "            slice_t2 = resized_t2_imgdata[:,:,i]\n",
    "            slice_flair = resized_flair_imgdata[:,:,i]\n",
    "            #remove zeroes slices\n",
    "            if (slice_t2==0).all() and (slice_flair==0).all():\n",
    "              continue\n",
    "\n",
    "            slice_t2 = np.rot90(slice_t2,1)\n",
    "            slice_flair = np.rot90(slice_flair,1)\n",
    "\n",
    "            fusion = np.hstack((slice_t2,slice_flair)).astype('uint8')\n",
    "            fn =patient+'_slice'+ str(i).zfill(3) + '.png'\n",
    "            outdir = png_path\n",
    "            outname = os.path.join(outdir, fn)\n",
    "\n",
    "            imageio.imwrite(outname, fusion, compress_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "\n",
    "PATH = #BLINDED\n",
    "\n",
    "BUFFER_SIZE = 400\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "# Load image as tensor and separate input and target(real_image)\n",
    "\n",
    "def load(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    w = w // 2\n",
    "    input_image = image[:, :w, :]\n",
    "    real_image = image[:, w:, :]\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "# Load and show a sample input(inp) and real/target(re)\n",
    "# inp and re will be used later on for further visualization\n",
    "\n",
    "inp, re = load(PATH+'/train_FLAIR_2_T2_pngs/100.png')\n",
    "\n",
    "\n",
    "# casting to int for matplotlib to show the image\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(inp/255.0)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(re/255.0)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "\n",
    "def resize(input_image, real_image, height, width):\n",
    "    input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def random_crop(input_image, real_image):\n",
    "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image[0], cropped_image[1]\n",
    "\n",
    "# normalizing the images to [-1, 1]\n",
    "def normalize(input_image, real_image):\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    real_image = (real_image / 127.5) - 1\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "@tf.function()\n",
    "def random_jitter(input_image, real_image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "    # random mirroring\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "# Load image and augment\n",
    "\n",
    "def load_image_train(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = random_jitter(input_image, real_image)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "def load_image_test(image_file):\n",
    "    input_image, real_image = load(image_file)\n",
    "    input_image, real_image = resize(input_image, real_image,\n",
    "                                   IMG_HEIGHT, IMG_WIDTH)\n",
    "    input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "    return input_image, real_image\n",
    "\n",
    "# Show example of random jittering\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "for i in range(4):\n",
    "    rj_inp, rj_re = random_jitter(inp, re)\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(rj_inp/255.0)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "\n",
    "# Train\n",
    "train_dataset = tf.data.Dataset.list_files(PATH+'/train_FLAIR_2_T2_pngs/*.png')\n",
    "train_dataset = train_dataset.map(load_image_train,\n",
    "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# Test\n",
    "test_dataset = tf.data.Dataset.list_files(PATH+'/val_FLAIR_2_T2_pngs/*.png')\n",
    "test_dataset = test_dataset.map(load_image_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "# downsample and upsample functions\n",
    "\n",
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "# downsample result\n",
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(tf.expand_dims(inp, 0))\n",
    "#print (f'Downsample result: {down_result.shape}')\n",
    "\n",
    "def upsample(filters, size, apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "# upsample result\n",
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(down_result)\n",
    "#print (f'Upsample result: {up_result.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "\n",
    "def Generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "    down_stack = [\n",
    "    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "    downsample(128, 4), # (bs, 64, 64, 128)\n",
    "    downsample(256, 4), # (bs, 32, 32, 256)\n",
    "    downsample(512, 4), # (bs, 16, 16, 512)\n",
    "    downsample(512, 4), # (bs, 8, 8, 512)\n",
    "    downsample(512, 4), # (bs, 4, 4, 512)\n",
    "    downsample(512, 4), # (bs, 2, 2, 512)\n",
    "    downsample(512, 4), # (bs, 1, 1, 512)\n",
    "    ]\n",
    "\n",
    "    up_stack = [\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "    upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "    upsample(256, 4), # (bs, 32, 32, 512)\n",
    "    upsample(128, 4), # (bs, 64, 64, 256)\n",
    "    upsample(64, 4), # (bs, 128, 128, 128)\n",
    "    ]\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# create generator and show architecture\n",
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "\n",
    "LAMBDA = 100\n",
    "\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "    return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "\n",
    "def Discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n",
    "\n",
    "# create discriminator and show architecture\n",
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10\n",
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11\n",
    "\n",
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "    print(display_list[0].shape)\n",
    "    print(type(display_list[0]))\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "    display_list[i] = display_list[i].numpy()\n",
    "\n",
    "    display_list[i] = np.array(display_list[i])\n",
    "\n",
    "    print(display_list[i].min())\n",
    "\n",
    "    display_list[i] = display_list[i] * 0.5 + 0.5\n",
    "\n",
    "    print(display_list[i].min())\n",
    "\n",
    "    display_list[i] *= 255.0\n",
    "\n",
    "    display_list[i] = display_list[i].clip(0.0, 255.0).astype(np.uint8)\n",
    "\n",
    "    print(type(display_list[i]))\n",
    "    print(display_list[i].dtype)\n",
    "    print(display_list[i].shape)\n",
    "\n",
    "\n",
    "    image = Image.fromarray(display_list[i])\n",
    "    image.save('example_output.png', format='PNG')\n",
    "    plt.show()\n",
    "\n",
    "    mse = (np.square(tar - prediction)).mean()\n",
    "    print (f'Mean Squared Error: {mse}')\n",
    "\n",
    "for example_input, example_target in test_dataset.take(1):\n",
    "    generate_images(generator, example_input, example_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "\n",
    "import datetime\n",
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_image, target, epoch):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, target], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
    "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
    "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
    "\n",
    "# Training Loop\n",
    "#   - Iterates over the number of epochs.\n",
    "#   - On each epoch it clears the display, and runs `generate_images` to show it's progress.\n",
    "#   - On each epoch it iterates over the training dataset, printing a '.' for each example.\n",
    "#   - It saves a checkpoint every 20 epochs.\n",
    "\n",
    "def fit(train_ds, epochs, test_ds):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "        for example_input, example_target in test_ds.take(1):\n",
    "            generate_images(generator, example_input, example_target)\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "        # Train\n",
    "        for n, (input_image, target) in train_ds.enumerate():\n",
    "            print('.', end='')\n",
    "            if (n+1) % 100 == 0:\n",
    "                print()\n",
    "            train_step(input_image, target, epoch)\n",
    "        print()\n",
    "\n",
    "        # saving (checkpoint) the model every 20 epochs\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                            time.time()-start))\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 13\n",
    "EPOCHS = 300\n",
    "# EPOCHS = 3\n",
    "\n",
    "fit(train_dataset, EPOCHS, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain nifti volumes from nifti inputs of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize as rsz\n",
    "import imageio\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_path = 'Inference'\n",
    "test_data_path =  r'Test_Dataset'  \n",
    "\n",
    "\n",
    "image_rows = 256\n",
    "image_cols = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = os.listdir(test_data_path)\n",
    "print(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nifti_mse(model, test_input, tar, image_rows, image_cols):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "\n",
    "    display_list[2] = display_list[2].numpy()\n",
    "    display_list[2] = np.array(display_list[2])\n",
    "    \n",
    "    display_list[2] = rsz(display_list[2], (image_rows, image_cols), order = 1, preserve_range=True)\n",
    "\n",
    "    display_list[2] = display_list[2] * 0.5 + 0.5\n",
    "    display_list[2] *= 255.0\n",
    "    display_list[2] = display_list[2].clip(0.0, 255.0).astype(np.uint8)\n",
    "\n",
    "    print(type(display_list[2]))\n",
    "\n",
    "    gan_slice = display_list[2]\n",
    "    gan_t2[:,:,z,:]=gan_slice\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    ## Generate arrays to measure MSE and SSI\n",
    "    \n",
    "    target_array = np.array(tar[0,:,:,0].numpy())\n",
    "    prediction_array = np.array(prediction[0,:,:,0].numpy())\n",
    "\n",
    "    mse_sklearn = mean_squared_error(target_array,prediction_array)\n",
    "    if mse_sklearn == 0:\n",
    "        psnr=100\n",
    "    else:\n",
    "        maxi = 255.0\n",
    "        psnr = 10*np.log10(maxi/ np.sqrt(mse_sklearn))\n",
    "    ssi = ssim(target_array,prediction_array)\n",
    "    metrics.append([patient,z,mse_sklearn,psnr,ssi])\n",
    "    \n",
    "    print (f'Sklearn MSE: {mse_sklearn}')\n",
    "    print (f'PSNR: {psnr}db')\n",
    "    print (f'SSI: {ssi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient in patients:\n",
    "    print(f'WORKING ON PATIENTS: {patient}')\n",
    "\n",
    "    patient_path = os.path.join(test_data_path,patient)\n",
    "#     studio = os.listdir(patient_path)\n",
    "#     scans =os.listdir(os.path.join(patient_path,studio[0]))\n",
    "    \n",
    "    ## Create the folders to store pngs and nifti\n",
    "    PNGs_dir = f'pngs_t2_{name}'\n",
    "    NIFTI_dir = f'nifti_t2_{name}'\n",
    "    png_dir = os.path.join(patient_path, PNGs_dir)\n",
    "    nifti_dir = os.path.join(patient_path, NIFTI_dir)\n",
    "#     os.mkdir(png_dir)\n",
    "#     os.mkdir(nifti_dir)\n",
    "    png_path= png_dir\n",
    "    nifti_path = nifti_dir\n",
    "    \n",
    "    scans =os.listdir(patient_path)\n",
    "    \n",
    "    print(scans)\n",
    "        \n",
    "    # Create the numpy arrays to generate pngs \n",
    "    for scan in scans:\n",
    "        if 't2.nii.gz' in scan:\n",
    "            t2path = os.path.join(patient_path,scan)\n",
    "            print(t2path)\n",
    "\n",
    "            t2_img = nib.load(t2path)\n",
    "            t2_imgdata = t2_img.get_fdata()\n",
    "            t2_imgdata = t2_imgdata.astype(np.float32)\n",
    "            t2_affine = t2_img.affine\n",
    "\n",
    "            resized_t2_imgdata = rsz(t2_imgdata, (256, 256), order = 1, preserve_range=True)\n",
    "            \n",
    "            resized_t2_imgdata -= resized_t2_imgdata.min()\n",
    "            resized_t2_imgdata *= 1./np.max(resized_t2_imgdata)\n",
    "            resized_t2_imgdata *= 255\n",
    "            resized_t2_imgdata = np.flipud(resized_t2_imgdata)\n",
    "\n",
    "\n",
    "        if 'flair.nii.gz' in scan:\n",
    "            flairpath = os.path.join(patient_path,scan)\n",
    "            print(flairpath)\n",
    "\n",
    "            flair_img = nib.load(flairpath)\n",
    "            flair_imgdata = flair_img.get_fdata()\n",
    "            flair_imgdata = flair_imgdata.astype(np.float32)\n",
    "            # the FLAIR affine will be used to build the nifti from gan's output\n",
    "            flair_affine = flair_img.affine\n",
    "\n",
    "            resized_flair_imgdata = rsz(flair_imgdata, (256, 256), order = 1, preserve_range=True)\n",
    "\n",
    "            resized_flair_imgdata -= resized_flair_imgdata.min()\n",
    "            resized_flair_imgdata *= 1./np.max(resized_flair_imgdata)\n",
    "            resized_flair_imgdata *= 255\n",
    "            resized_flair_imgdata = np.flipud(resized_flair_imgdata)\n",
    "            \n",
    "    ## use the numpy arrays to generate pngs              \n",
    "    for i in range(0,resized_flair_imgdata.shape[2]):\n",
    "        slice_t2 = resized_t2_imgdata[:,:,i]\n",
    "        slice_flair = resized_flair_imgdata[:,:,i]\n",
    "\n",
    "        slice_t2 = np.rot90(slice_t2,1)\n",
    "        slice_flair = np.rot90(slice_flair,1)\n",
    "\n",
    "        ## generates the input for pix2pix stack: INPUT -> TARGET\n",
    "        fusion = np.hstack((slice_flair,slice_t2)).astype('uint8')\n",
    "        fn = str(i).zfill(3) + '.png'\n",
    "        outdir = png_path\n",
    "        outname = os.path.join(outdir, fn)\n",
    "        imageio.imwrite(outname, fusion, compress_level=0)\n",
    "        \n",
    "    gan_t2 = np.ndarray((flair_imgdata.shape[1],flair_imgdata.shape[0],flair_imgdata.shape[2],3)) # the last axis is 3 because it's rgb, but we need only one\n",
    "\n",
    "    # Predictions input\n",
    "    test_prediction = tf.data.Dataset.list_files(outdir+'/*.png', shuffle=False)\n",
    "    test_prediction = test_prediction.map(load_image_test)\n",
    "    test_prediction = test_prediction.batch(BATCH_SIZE)\n",
    "\n",
    "    ## Run the trained pix2pix model on the patient\n",
    "    z = 0\n",
    "    print('Generating the metrics list')\n",
    "    metrics = []\n",
    "    for inp, tar in test_prediction.take(-1):\n",
    "        generate_nifti_mse(generator, inp, tar, flair_imgdata.shape[1], flair_imgdata.shape[0]) \n",
    "        print(f'Slice number: {z}')\n",
    "        z +=1\n",
    "        \n",
    "    # Generate the nifti file from the output of pix2pix\n",
    "\n",
    "    \n",
    "    nifti_img=np.copy(gan_t2[:,:,:,0])\n",
    "    nifti_img = np.flipud(nifti_img)\n",
    "    nifti_img = nifti_img.astype(np.float32)\n",
    "    gan_flair_nifti = nib.Nifti1Image(np.flipud(np.rot90(np.fliplr(nifti_img),1)), affine=flair_img.affine)\n",
    "#     nib.save(gan_flair_nifti, nifti_dir+'/gt2.nii.gz')\n",
    "    \n",
    "    # Generate dataframe with evaluation metrics for each patient and slice\n",
    "    df = pd.DataFrame(metrics, columns=[\"PID\",\"Slice\",\"MSE\",\"PSNR\",\"SSI\"])\n",
    "    df.to_csv(f'BLINDED_flair2t2.csv', mode='a',header=False)\n",
    "    \n",
    "    print('==================================================================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
